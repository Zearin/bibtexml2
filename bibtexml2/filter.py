# -*- coding: utf-8 -*-
'''Pygments-style filters.'''

##  StdLib
from __future__ import (
    absolute_import, 
    with_statement, 
    print_function,)
    

##  External
from pygments.util import get_bool_opt
from pygments.token import Name
from pygments.filter import (
    Filter,         # for class-based filters
    simplefilter,   # for decorator-based filters
    )


@simplefilter
def token_types(lexer, stream, options):
    '''
    '''
    for ttype, value in stream:
        pass  # TODO


### 
### COMMENTS
### 
# (Token.Comment, u'Any changes to this file will be lost if it is regenerated by Mendeley.\n')
# (Token.Comment, u'Automatically generated by Mendeley 1.8\n')
# 
# 
# ###
# ### ENTRIES
# ###
# (Token.Keyword.Declaration, u'@article')
# (Token.Keyword.Declaration, u'@book')
# (Token.Keyword.Declaration, u'@inbook')
# (Token.Keyword.Declaration, u'@inproceedings')
# (Token.Keyword.Declaration, u'@misc')
# (Token.Keyword.Declaration, u'@phdthesis')
# (Token.Keyword.Declaration, u'@proceedings')
# (Token.Keyword.Declaration, u'@techreport')
# 
# ###
# ### ID-LABELS
# ###
# (Token.Name.Label, u'1104446')
# (Token.Name.Label, u'1183470')
# (Token.Name.Label, u'1225706')
# (Token.Name.Label, u'1241011')
# (Token.Name.Label, u'1350753')
# (Token.Name.Label, u'1350758')
# ### ...snip...
# 
# 
# ###
# ### FIELDS
# ###
# (Token.Name.Attribute, u'abstract')
# (Token.Name.Attribute, u'address')
# (Token.Name.Attribute, u'annote')
# (Token.Name.Attribute, u'archivePrefix')
# (Token.Name.Attribute, u'arxivId')
# (Token.Name.Attribute, u'author')
# (Token.Name.Attribute, u'booktitle')
# (Token.Name.Attribute, u'chapter')
# (Token.Name.Attribute, u'doi')
# (Token.Name.Attribute, u'edition')
# (Token.Name.Attribute, u'editor')
# (Token.Name.Attribute, u'eprint')
# (Token.Name.Attribute, u'file')
# (Token.Name.Attribute, u'institution')
# (Token.Name.Attribute, u'isbn')
# (Token.Name.Attribute, u'issn')
# (Token.Name.Attribute, u'journal')
# (Token.Name.Attribute, u'keywords')
# (Token.Name.Attribute, u'language')
# (Token.Name.Attribute, u'month')
# (Token.Name.Attribute, u'number')
# (Token.Name.Attribute, u'organization')
# (Token.Name.Attribute, u'pages')
# (Token.Name.Attribute, u'publisher')
# (Token.Name.Attribute, u'school')
# (Token.Name.Attribute, u'series')
# (Token.Name.Attribute, u'shorttitle')
# (Token.Name.Attribute, u'title')
# (Token.Name.Attribute, u'type')
# (Token.Name.Attribute, u'url')
# (Token.Name.Attribute, u'volume')
# (Token.Name.Attribute, u'year')
# 
# 
# ###
# ### VALUES
# ###
# (Token.Literal.String.Double, u":Users/amrogers/Library/Application Support/Mendeley Desktop/Documents/2002/Golbeck/Golbeck - 2002 - Evolving Strategies for the Prisoner's Dilemma.pdf:pdf")
# (Token.Literal.String.Double, u":Users/amrogers/Library/Application Support/Mendeley Desktop/Documents/2003/Golbeck et al/Golbeck et al. - 2003 - The National Cancer Institute's Thesaurus and Ontology.pdf:pdf")
# (Token.Literal.String.Double, u":Users/amrogers/Library/Application Support/Mendeley Desktop/Documents/2007/Mannes, Golbeck/Mannes, Golbeck - 2007 - Ontology Building A Terrorism Specialist's Perspective.pdf:pdf")
# (Token.Literal.String.Double, u":Users/amrogers/Library/Application Support/Mendeley Desktop/Documents/2008/Golbeck, Hendler/Golbeck, Hendler - 2008 - Metcalfe's Law, Web 2.0, and the Semantic Web.pdf:pdf")
# (Token.Literal.String.Double, u"Aberer, Karl and Choi, Key-Sun and Noy, Natasha and Allemang, Dean and Lee, Kyung-Il and Nixon, Lyndon and Golbeck, Jennifer and Mika, Peter and Maynard, Diana and Mizoguchi, Riichiro and Schreiber, Guus and Cudr\\'")
# (Token.Literal.String.Double, u"ASIS&T '10")
# (Token.Literal.String.Double, u"ASIS&T '10: Proceedings of the 73rd ASIS&T Annual Meeting on Navigating Streams in an Information Ecosystem")
# (Token.Literal.String.Double, u"C&T '09")
# (Token.Literal.String.Double, u"CHI '09")
# (Token.Literal.String.Double, u"CHI '10: Proceedings of the 28th international conference on Human factors in computing systems")
# (Token.Literal.String.Double, u"CHI '12")
# (Token.Literal.String.Double, u"CHI EA '08")
# (Token.Literal.String.Double, u"CHI EA '09")
# (Token.Literal.String.Double, u"CHI EA '12")
# (Token.Literal.String.Double, u"Companies are now making video-communication systems that allow pet owners to see, and, in some cases, even interact with their pets when they are separated by distance. Such 'doggie cams' show promise, yet it is not clear how pet video chat systems should be designed (if at all) in order to meet the real needs of pet owners. To investigate the potential of interactive dog cams, we then designed our own pet video chat system that augments a Skype audio-video connection with remote interaction features and evaluated it with pet owners to understand its usage. Our results show promise for pet video chat systems that allow owners to see and interact with their pets while away.")
# ### ...snip...
# 
# 
# ###
# ### SPECIAL values
# ###
# (Token.Text, u'apr')
# (Token.Text, u'aug')
# (Token.Text, u'dec')
# (Token.Text, u'feb')
# (Token.Text, u'jan')
# (Token.Text, u'jul')
# (Token.Text, u'jun')
# (Token.Text, u'mar')
# (Token.Text, u'may')
# (Token.Text, u'nov')
# (Token.Text, u'oct')
# (Token.Text, u'sep')
# 
# 
# 
# 
# ###
# ### MISC token noise
# ###
# (Token.Punctuation, u',')
# (Token.Punctuation, u'{')
# (Token.Punctuation, u'}')
# 
# (Token.Text, u' ')
# (Token.Text, u' =')
# (Token.Text, u'\n')
